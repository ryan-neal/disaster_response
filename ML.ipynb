{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from helpers import get_database_url\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from wordcounter.py import WordCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    url = get_database_url()\n",
    "    engine = create_engine(url)\n",
    "    df = pd.read_sql_table(\"message_categories\", engine)\n",
    "    X = df[\"message\"]\n",
    "    Y = df[df.columns[3:]]\n",
    "    Y = Y.astype(int)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tokenize message data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(series):\n",
    "    \n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(\"\\w+|\\d+\")\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    for row in series:\n",
    "        clean = tokenizer.tokenize(row.lower())\n",
    "        tokens.append(clean)\n",
    "        \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        #tok = list(set(tok) - set(stop_words))\n",
    "        clean_tok = lemmatizer.lemmatize(str(tok)).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build a simple machine learning pipeline </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(classifier):\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            (\"clf\", MultiOutputClassifier(classifier))\n",
    "        ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(classifier):\n",
    "    X, Y = load_data()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "    model = model_pipeline(classifier)\n",
    "    model.fit(X_train.values, Y_train.values)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    display_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_score(Y_true, Y_pred):\n",
    "    Y_pred_df = convert_to_dataframe(Y_pred)\n",
    "    for column in Y_true.columns:\n",
    "        precision, recall, fscore, support = score(Y_true[column], Y_pred_df[column], average=\"weighted\")\n",
    "        print(column, precision, recall, fscore, support)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(test_data):\n",
    "    test_df = pd.DataFrame(test_data, columns = Y.columns)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related 0.7586420271294321 0.7815074763503204 0.7260642589078131 None\n",
      "request 0.8435754645616177 0.8515410436374733 0.8137251745582504 None\n",
      "offer 0.9917777280719161 0.9958803783948733 0.9938248191702986 None\n",
      "aid_related 0.660382400052106 0.6643271284711626 0.6467866247493009 None\n",
      "medical_help 0.9033622640126706 0.9197436679890143 0.8823297808811464 None\n",
      "medical_products 0.9012465248383629 0.9491913335367714 0.9245978046600066 None\n",
      "search_and_rescue 0.94909334708046 0.9742142203234666 0.9614897282271172 None\n",
      "security 0.9643129113981111 0.9818431492218492 0.9729990774334931 None\n",
      "military 0.934872254266647 0.9667378700030516 0.9505380732675465 None\n",
      "child_alone 1.0 1.0 1.0 None\n",
      "water 0.9435045979281592 0.9398840402807446 0.9124851196896309 None\n",
      "food 0.8738173553661184 0.892584681110772 0.8489922962026628 None\n",
      "shelter 0.8940177406319862 0.9021971315227342 0.8574304447807959 None\n",
      "clothing 0.9694166087997939 0.9845895636252671 0.9769441768392172 None\n",
      "money 0.9538559218693385 0.9766554775709491 0.9651210670677953 None\n",
      "missing_people 0.9772441645561593 0.988556606652426 0.9828678361852324 None\n",
      "refugees 0.9339921884610367 0.9664327128471163 0.9499355684626993 None\n",
      "death 0.9474148995893191 0.9563625267012511 0.9356250625045597 None\n",
      "other_aid 0.8016076951588549 0.8707659444613977 0.8110490160450033 None\n",
      "infrastructure_related 0.8719467639047416 0.9337808971620385 0.901805127131399 None\n",
      "transport 0.9591040034373618 0.957277998169057 0.9368316002893808 None\n",
      "buildings 0.9268424154470087 0.9493439121147391 0.9252693708315515 None\n",
      "electricity 0.9613213072049773 0.9804699420201404 0.9708012091558432 None\n",
      "tools 0.9869212874261003 0.9934391211473909 0.9901694784218389 None\n",
      "hospitals 0.9763393787104601 0.988098870918523 0.9821839275622954 None\n",
      "shops 0.9920816513760613 0.996032956972841 0.9940533776362491 None\n",
      "aid_centers 0.9724234823320338 0.9861153494049435 0.9792215569185143 None\n",
      "other_infrastructure 0.9157970184367256 0.9569728410131217 0.935932271765835 None\n",
      "weather_related 0.7897430498721775 0.7909673481843149 0.7582086782924861 None\n",
      "floods 0.914023025043175 0.9202014037229173 0.8846772169376278 None\n",
      "storm 0.8944385770361375 0.9150137320720171 0.8778198476644639 None\n",
      "fire 0.9802631438040759 0.9900823924321025 0.9851483009264607 None\n",
      "earthquake 0.943982381003981 0.9478181263350626 0.9437579085227873 None\n",
      "cold 0.9649123754708038 0.9821483063777846 0.9734540522608233 None\n",
      "other_weather 0.9000954395999751 0.9487335978028685 0.9237747433664637 None\n",
      "direct_report 0.8186630403043222 0.8291119926762283 0.784513571326216 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanneal/Desktop/data_science/disaster_response/disaster/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "main(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = WordCounter()\n",
    "print(counter.transform(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disaster",
   "language": "python",
   "name": "disaster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
